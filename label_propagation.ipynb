{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abb059ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import noisereduce as nr\n",
    "import librosa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from joblib import dump, load\n",
    "\n",
    "# Step 1: Convert MP3 to WAV\n",
    "def mp3_to_wav(input_path, output_path):\n",
    "    audio = AudioSegment.from_mp3(input_path)\n",
    "    audio.export(output_path, format=\"wav\")\n",
    "\n",
    "# Step 2: Preprocessing with Silence Removal\n",
    "def preprocess_audio(file_path, sr=48000):\n",
    "    # Load audio\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "    \n",
    "    # Remove silence\n",
    "    reduced_noise = nr.reduce_noise(y=y, sr=sr, stationary=True)\n",
    "    \n",
    "    # Trim silent parts\n",
    "    y_trimmed, _ = librosa.effects.trim(reduced_noise, top_db=20)\n",
    "    \n",
    "    return y_trimmed, sr\n",
    "\n",
    "# Step 3: Feature Extraction (46 features)\n",
    "def extract_features(y, sr=48000):\n",
    "    features = []\n",
    "    \n",
    "    # MFCCs (40 coefficients)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    features.extend(np.mean(mfccs, axis=1))\n",
    "    \n",
    "    # Spectral Features\n",
    "    S = np.abs(librosa.stft(y))\n",
    "    \n",
    "    # Spectral Centroid\n",
    "    centroid = librosa.feature.spectral_centroid(S=S)\n",
    "    features.append(np.mean(centroid))\n",
    "    \n",
    "    # Spectral Bandwidth\n",
    "    bandwidth = librosa.feature.spectral_bandwidth(S=S)\n",
    "    features.append(np.mean(bandwidth))\n",
    "    \n",
    "    # Spectral Contrast\n",
    "    contrast = librosa.feature.spectral_contrast(S=S)\n",
    "    features.extend(np.mean(contrast, axis=1))\n",
    "    \n",
    "    # Spectral Roll-Off (85%)\n",
    "    rolloff = librosa.feature.spectral_rolloff(S=S, roll_percent=0.85)\n",
    "    features.append(np.mean(rolloff))\n",
    "    \n",
    "    # Spectral Flatness\n",
    "    flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    features.append(np.mean(flatness))\n",
    "    \n",
    "    # Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    features.append(np.mean(zcr))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "def get_records_and_labels(metadata_path, audio_dir, num_per_label=-1):\n",
    "    df = pd.read_csv(metadata_path, sep='\\t')\n",
    "    df = df[df['age'].notna() & df['gender'].notna() & df['label'].notna()]\n",
    "\n",
    "    balanced_df = df\n",
    "\n",
    "    num_files = sum(1 for entry in os.scandir(audio_dir) if entry.is_file())\n",
    "    print(f\"Number of files in directory: {num_files}\")\n",
    "    print(f\"Number of records in DataFrame: {len(df)}\")\n",
    "\n",
    "    with open(\"error_file_paths.txt\", \"r\") as f:\n",
    "        error_file_paths = f.read().splitlines()\n",
    "    valid_indices = []\n",
    "    for idx, row in tqdm(balanced_df.iterrows(), total=len(balanced_df), desc=\"Checking files\"):\n",
    "        file_path = os.path.join(audio_dir, row['path'])\n",
    "        if os.path.exists(file_path) and file_path not in error_file_paths and row['down_votes'] == 0: \n",
    "            valid_indices.append(idx)\n",
    "\n",
    "    balanced_df = balanced_df.loc[valid_indices]\n",
    "    print(f\"Records with existing files: {len(balanced_df)}\")\n",
    "\n",
    "    if num_per_label == -1:\n",
    "        return balanced_df\n",
    "\n",
    "    return balanced_df.groupby('label').apply(lambda x: x.sample(n=num_per_label, random_state=42) if len(x) >= num_per_label else x).reset_index(drop=True)\n",
    "\n",
    "# Main Processing Pipeline\n",
    "def process_dataset(df, input_audio_dir, output_audio_dir, output_csv):\n",
    "    features_list = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extracting features\"):\n",
    "        filename = row['path']\n",
    "\n",
    "        mp3_path = os.path.join(input_audio_dir, filename)\n",
    "        wav_path = os.path.join(output_audio_dir, filename.replace(\".mp3\", \".wav\"))\n",
    "        mp3_to_wav(mp3_path, wav_path)\n",
    "        \n",
    "        # Preprocess\n",
    "        y, sr = preprocess_audio(wav_path)\n",
    "        \n",
    "        # Extract features\n",
    "        features = extract_features(y, sr)\n",
    "        \n",
    "        # Get label\n",
    "        age_label = row['label']  \n",
    "        \n",
    "        features_list.append(features)\n",
    "        labels.append(age_label)\n",
    "    \n",
    "    # Normalization\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features_list)\n",
    "    save_model(scaler, filename=\"scaler.joblib\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(scaled_features)\n",
    "    df['label'] = labels\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "def save_model(model, save_dir=\"models\", filename=\"model.joblib\"):\n",
    "    # Create directory if needed\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    dump(model, os.path.join(save_dir, filename))\n",
    "\n",
    "    print(f\"Models saved to {save_dir} directory\")\n",
    "\n",
    "def load_models(model_dir=\"models\", model_names=[\"knn_model.joblib\", \"lp_model.joblib\", \"scaler.joblib\"]):\n",
    "    models = {}\n",
    "    for model_name in model_names:\n",
    "        model_path = os.path.join(model_dir, model_name)\n",
    "        if os.path.exists(model_path):\n",
    "            models[model_name] = load(model_path)\n",
    "        else:\n",
    "            print(f\"Model {model_name} not found in {model_dir}.\")\n",
    "    return models\n",
    "\n",
    "def predict_age(audio_path, models_dir=\"models\", model_names=[\"knn_model.joblib\", \"lp_model.joblib\", \"scaler.joblib\"]):\n",
    "    # Load models and scaler\n",
    "    knn_model, lp_model, scaler = load_models(models_dir, model_names)\n",
    "    \n",
    "    # Preprocess audio\n",
    "    y, sr = preprocess_audio(audio_path)\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(y, sr)\n",
    "    \n",
    "    # Scale features\n",
    "    scaled_features = scaler.transform([features])\n",
    "    \n",
    "    # Make predictions\n",
    "    knn_pred = knn_model.predict(scaled_features)\n",
    "    lp_pred = lp_model.predict(scaled_features)\n",
    "    \n",
    "    return {\n",
    "        \"knn_prediction\": knn_pred[0],\n",
    "        \"lp_prediction\": lp_pred[0]\n",
    "    }\n",
    "\n",
    "# Classification\n",
    "def train_and_evaluate(csv_path): \n",
    "    # Load dataset\n",
    "    data = pd.read_csv(csv_path)\n",
    "    X = data.drop('label', axis=1).values\n",
    "    y = data['label'].values  \n",
    "\n",
    "    # Split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Initialize classifiers\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    lp = LabelPropagation(kernel='knn', gamma=0.1)\n",
    "    \n",
    "    # Train and evaluate\n",
    "    for clf, name in [(knn, 'KNN'), (lp, 'Label Propagation')]:\n",
    "        print(f\"Training {name}...\")\n",
    "        start_train = time.perf_counter()\n",
    "        with tqdm(total=1, desc=f\"Training {name}\", leave=False) as pbar:\n",
    "            clf.fit(X_train, y_train)\n",
    "            pbar.update(1)\n",
    "        train_duration = time.perf_counter() - start_train\n",
    "\n",
    "        start_pred = time.perf_counter()\n",
    "        with tqdm(total=1, desc=f\"Predicting {name}\", leave=False) as pbar:\n",
    "            y_pred = clf.predict(X_test)\n",
    "            pbar.update(1)\n",
    "        pred_duration = time.perf_counter() - start_pred\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{name} Accuracy: {acc}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(f\"- Training time: {train_duration:.2f} seconds\")\n",
    "        print(f\"- Prediction time: {pred_duration:.4f} seconds\")\n",
    "\n",
    "        save_model(clf, filename=f\"{name}_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc5313c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"..\\\\filtered_data_labeled.tsv\"\n",
    "audio_dir = \"..\\\\filtered_clips\"\n",
    "output_audio_dir = \"..\\\\wav_audio_dataset8000\"\n",
    "features_csv = \"features8000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03125364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in directory: 192727\n",
      "Number of records in DataFrame: 222104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking files: 100%|██████████| 222104/222104 [01:02<00:00, 3538.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with existing files: 152422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\islam\\AppData\\Local\\Temp\\ipykernel_17156\\2553231520.py:95: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return balanced_df.groupby('label').apply(lambda x: x.sample(n=num_per_label, random_state=42) if len(x) >= num_per_label else x).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "df = get_records_and_labels(metadata_path, audio_dir, num_per_label=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87432f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/8000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "process_dataset(df, audio_dir, output_audio_dir, features_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab438ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.8282362246243079\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.76      1964\n",
      "           1       0.89      0.85      0.87      2011\n",
      "           2       0.80      0.87      0.83      1978\n",
      "           3       0.81      0.88      0.85      1633\n",
      "\n",
      "    accuracy                           0.83      7586\n",
      "   macro avg       0.83      0.83      0.83      7586\n",
      "weighted avg       0.83      0.83      0.83      7586\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1409   60  397   98]\n",
      " [  62 1715   20  214]\n",
      " [ 218   19 1715   26]\n",
      " [  37  133   19 1444]]\n",
      "- Training time: 0.01 seconds\n",
      "- Prediction time: 1.0868 seconds\n",
      "Models saved to models directory\n",
      "Training Label Propagation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Propagation Accuracy: 0.8253361455312418\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1964\n",
      "           1       0.89      0.85      0.87      2011\n",
      "           2       0.80      0.86      0.83      1978\n",
      "           3       0.80      0.88      0.84      1633\n",
      "\n",
      "    accuracy                           0.83      7586\n",
      "   macro avg       0.83      0.83      0.82      7586\n",
      "weighted avg       0.83      0.83      0.82      7586\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1410   53  397  104]\n",
      " [  61 1714   23  213]\n",
      " [ 227   14 1701   36]\n",
      " [  36  144   17 1436]]\n",
      "- Training time: 8.47 seconds\n",
      "- Prediction time: 1.0511 seconds\n",
      "Models saved to models directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(features_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec46f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
