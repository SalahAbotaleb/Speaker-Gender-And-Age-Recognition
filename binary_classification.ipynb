{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8015d5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\Python312\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.2.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "import os\n",
    "\n",
    "# Load the models\n",
    "model0 = load(os.path.join('trials\\\\binary_classification_log_mel_energy\\\\class_0_SVM\\\\model.joblib'))\n",
    "model1 = load(os.path.join('trials\\\\binary_classification_log_mel_energy\\\\class_1_SVM\\\\model.joblib'))\n",
    "model2 = load(os.path.join('trials\\\\binary_classification_log_mel_energy\\\\class_2_SVM\\\\model.joblib'))\n",
    "model3 = load(os.path.join('trials\\\\binary_classification_log_mel_energy\\\\class_3_SVM\\\\model.joblib'))\n",
    "model_gender = load(os.path.join('trials\\\\log_mel_energy_Gender_Age\\\\Gender\\\\model.joblib'))\n",
    "\n",
    "print(\"Models loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6d67403",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load(os.path.join('trials\\\\features\\\\48k_mfcc_extra_hfcc_extra\\\\X_train.joblib'))\n",
    "X_train2 = load(os.path.join('trials\\\\features\\\\48k_log_mel_energy_all_data\\\\X_train.joblib'))\n",
    "y_train = load(os.path.join('trials\\\\features\\\\48k_mfcc_extra_hfcc_extra\\\\y_train.joblib'))\n",
    "\n",
    "X_test = load(os.path.join('trials\\\\features\\\\48k_mfcc_extra_hfcc_extra\\\\X_test.joblib'))\n",
    "X_test2 = load(os.path.join('trials\\\\features\\\\48k_log_mel_energy_all_data\\\\X_test.joblib'))\n",
    "y_test = load(os.path.join('trials\\\\features\\\\48k_mfcc_extra_hfcc_extra\\\\y_test.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7d59472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172786, 375)\n",
      "(9094, 375)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train_combined = np.concatenate((X_train[:,:150], X_train[:,7*75:9*75], X_train2[:,-75:]), axis=1)\n",
    "X_test_combined = np.concatenate((X_test[:,:150], X_test[:,7*75:9*75], X_test2[:,-75:]), axis=1)\n",
    "print(X_train_combined.shape)\n",
    "print(X_test_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfd2e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:00<00:00, 32.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for one prediction: 0.033996 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CombinedModel(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model0=None, model1=None, model2=None, model3=None, model_gender=None):\n",
    "        self.model0 = model0\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.model_gender = model_gender\n",
    "        \n",
    "\n",
    "    def predict_one(self, X):\n",
    "        # Collect predictions from all models\n",
    "        \n",
    "\n",
    "        # if prediction3 == 0:\n",
    "        #     prediction1 = self.model1.predict(X)\n",
    "        #     if prediction1 == 0:\n",
    "        #         prediction2 = self.model2.predict(X)\n",
    "        #         if prediction2 == 0:\n",
    "        #             final_predictions = 0\n",
    "        #         else:\n",
    "        #             prediction0 = self.model0.predict(X)\n",
    "        #             if prediction0 == 0:\n",
    "        #                 final_predictions = 2\n",
    "        #             else:\n",
    "        #                 final_predictions = 0\n",
    "        #     else:\n",
    "        #         prediction2 = self.model2.predict(X)\n",
    "        #         if prediction2 == 0:\n",
    "        #             final_predictions = 1\n",
    "        #         else:\n",
    "        #             final_predictions = 2\n",
    "        # else:\n",
    "        #     prediction1 = self.model1.predict(X)\n",
    "        #     if prediction1 == 0:\n",
    "        #         prediction2 = self.model2.predict(X)\n",
    "        #         if prediction2 == 0:\n",
    "        #             final_predictions = 3\n",
    "        #         else:\n",
    "        #             final_predictions = 2\n",
    "        #     else:\n",
    "        #         prediction0 = self.model0.predict(X)\n",
    "        #         if prediction0 == 0:\n",
    "        #             final_predictions = 3\n",
    "        #         else:\n",
    "        #             final_predictions = 1\n",
    "\n",
    "        final_predictions = None\n",
    "        prediction_gender = model_gender.predict(X)\n",
    "        if prediction_gender == 0:\n",
    "            prediction0 = self.model0.predict(X)\n",
    "            prediction2 = self.model2.predict(X)\n",
    "\n",
    "            if prediction0 == 1:\n",
    "                final_predictions = 0\n",
    "            elif prediction2 == 1:\n",
    "                final_predictions = 2\n",
    "            else:\n",
    "                prediction1 = self.model1.predict(X)\n",
    "                if prediction1 == 1:\n",
    "                    final_predictions = 1\n",
    "                else:\n",
    "                    final_predictions = 0\n",
    "            \n",
    "        else:\n",
    "            prediction1 = self.model1.predict(X)\n",
    "            prediction3 = self.model3.predict(X)\n",
    "            if prediction1 == 1:\n",
    "                final_predictions = 1\n",
    "            elif prediction3 == 1:\n",
    "                final_predictions = 3\n",
    "            else:\n",
    "                prediction0 = self.model0.predict(X)\n",
    "                if prediction0 == 1:\n",
    "                    final_predictions = 3\n",
    "                else:\n",
    "                    final_predictions = 2\n",
    "\n",
    "        return final_predictions\n",
    "\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Apply predict_one for each sample in X\n",
    "        return np.array([self.predict_one(sample.reshape(1, -1)) for sample in tqdm(X, desc=\"Predicting\")])\n",
    "# Create an instance of the combined model\n",
    "combined_model = CombinedModel(model0=model0, model1=model1, model2=model2, model3=model3, model_gender=model_gender)\n",
    "# Measure the time taken for one prediction\n",
    "start_time = time.time()\n",
    "combined_model.predict(X_val_fold[:1])  # Predict for one sample\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken for one prediction: {end_time - start_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "895df119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 8640/8640 [02:41<00:00, 53.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "train_idx, val_idx = next(skf.split(X_train_combined, y_train))\n",
    "\n",
    "X_train_fold, X_val_fold = X_train_combined[train_idx], X_train_combined[val_idx]\n",
    "y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "X_train_balanced, y_train_balanced = X_train_fold, y_train_fold\n",
    "\n",
    "\n",
    "y_val_pred = combined_model.predict(X_val_fold)\n",
    "#y_val_pred_proba_3 = clf.predict_proba(X_val_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57f38a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.997539305\n",
      "Accuracy: 0.998958333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5907\n",
      "           1       1.00      1.00      1.00      1029\n",
      "           2       1.00      0.99      1.00       922\n",
      "           3       1.00      1.00      1.00       782\n",
      "\n",
      "    accuracy                           1.00      8640\n",
      "   macro avg       1.00      1.00      1.00      8640\n",
      "weighted avg       1.00      1.00      1.00      8640\n",
      "\n",
      "[[5907    0    0    0]\n",
      " [   0 1028    1    0]\n",
      " [   7    0  915    0]\n",
      " [   0    0    1  781]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  balanced_accuracy_score\n",
    "\n",
    "print('Balanced Accuracy: %.9f' % (balanced_accuracy_score(y_val_fold, y_val_pred)))\n",
    "print('Accuracy: %.9f' % (accuracy_score(y_val_fold, y_val_pred)))\n",
    "print(classification_report(y_val_fold, y_val_pred))\n",
    "print(confusion_matrix(y_val_fold, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4b23498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 9094/9094 [02:51<00:00, 53.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.974598636\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      6217\n",
      "           1       0.98      0.96      0.97      1084\n",
      "           2       0.93      0.90      0.91       971\n",
      "           3       0.97      0.95      0.96       822\n",
      "\n",
      "    accuracy                           0.97      9094\n",
      "   macro avg       0.97      0.95      0.96      9094\n",
      "weighted avg       0.97      0.97      0.97      9094\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6167    8   26   16]\n",
      " [  12 1042   23    7]\n",
      " [  98    0  873    0]\n",
      " [  14   11   16  781]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict on the test set\n",
    "y_test_pred = combined_model.predict(X_test_combined)\n",
    "\n",
    "# Print accuracy\n",
    "print('Test Accuracy: %.9f' % (accuracy_score(y_test, y_test_pred)))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47f70943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.950601731\n"
     ]
    }
   ],
   "source": [
    "print('Balanced Accuracy: %.9f' % (balanced_accuracy_score(y_test, y_test_pred)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
