{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from preprocessing.noise_reduction import NoiseReducer\n",
    "from preprocessing.silence_removal import SilenceRemover\n",
    "from feature_extraction.mfcc import MFCC\n",
    "from feature_extraction.fundamental_frequency import FundamentalFrequency\n",
    "from feature_extraction.jitter import Jitter\n",
    "from feature_extraction.hfcc import HFCC\n",
    "from models.svm import SVM\n",
    "from audio import Audio\n",
    "\n",
    "original_metadata_path = os.path.join(\".\", \"data\", \"original_data_labeled.tsv\")\n",
    "filtered_metadata_path = os.path.join(\".\", \"data\", \"filtered_data_labeled.tsv\")\n",
    "audio_dir = os.path.join(\".\", \"data\", \"filtered_clips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove records of erroneous data (e.g. missing or corrupted audio files) from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(filtered_metadata_path):\n",
    "  df = pd.read_csv(original_metadata_path, sep='\\t')\n",
    "\n",
    "  # Remove unnecessary columns\n",
    "  df.drop(columns=['client_id', 'sentence', 'age', 'gender', 'accent'], inplace=True, errors='ignore')\n",
    "\n",
    "  # Filter out rows with missing labels\n",
    "  df = df[df['label'].notna()]\n",
    "\n",
    "  with open('error_file_paths.txt', 'r') as f:\n",
    "      error_file_paths = f.read().splitlines()\n",
    "\n",
    "  # Convert file paths to just the filename portion\n",
    "  error_file_paths = [os.path.basename(path) for path in error_file_paths]\n",
    "\n",
    "  # Remove rows with file paths in the error_file_paths list\n",
    "  df.drop(df[df['path'].isin(error_file_paths)].index, inplace=True)\n",
    "\n",
    "  valid_indices = []\n",
    "  for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking files\"):\n",
    "    file_path = os.path.join(audio_dir, row['path'])\n",
    "    if os.path.exists(file_path):\n",
    "      valid_indices.append(idx)\n",
    "\n",
    "  # Use only records with existing files\n",
    "  df = df.loc[valid_indices]\n",
    "\n",
    "  # Save the filtered DataFrame to a new TSV file\n",
    "  df.to_csv(filtered_metadata_path, sep='\\t', index=False)\n",
    "else:\n",
    "  df = pd.read_csv(filtered_metadata_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sorted unique labels\n",
    "labels = sorted(df['label'].unique())\n",
    "\n",
    "# Define bin edges so bars are centered on labels\n",
    "bin_edges = np.arange(min(labels) - 0.5, max(labels) + 1.5, 1)\n",
    "\n",
    "plt.hist(df['label'], bins=bin_edges, rwidth=0.8)\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xticks(labels)  # Set ticks to the actual labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a 2D histogram (heatmap) of upvotes vs downvotes\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist2d(df['up_votes'], df['down_votes'], bins=(100, 100), range=[(0, 100), (0, 100)], cmap='viridis', cmin=1, cmax=2000)\n",
    "plt.colorbar(label='Frequency')\n",
    "\n",
    "plt.title(\"2D Histogram of Upvotes vs Downvotes\")\n",
    "plt.xlabel(\"Upvotes\")\n",
    "plt.ylabel(\"Downvotes\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 100 #df['label'].value_counts().min()\n",
    "balanced_samples = pd.DataFrame()\n",
    "for cls in df['label'].unique():\n",
    "    cls_df = df[df['label'] == cls]\n",
    "    sampled = cls_df.sample(n=samples, random_state=42)  # Random sampling\n",
    "    balanced_samples = pd.concat([balanced_samples, sampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_reducer = NoiseReducer()\n",
    "silence_remover = SilenceRemover()\n",
    "fundamental_freq = FundamentalFrequency()\n",
    "jitter = Jitter()\n",
    "hfcc = HFCC()\n",
    "mfcc = MFCC()\n",
    "svm = SVM()\n",
    "\n",
    "feature_union = FeatureUnion([\n",
    "    ('mfcc', mfcc),\n",
    "    ('fundamental_freq', fundamental_freq),\n",
    "    ('jitter', jitter),\n",
    "    ('hfcc', hfcc)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipe = make_pipeline(noise_reducer, silence_remover, feature_union, verbose=True)\n",
    "feature_pipe\n",
    "\n",
    "def process_in_chunks(df, pipeline, chunk_size=100):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i in tqdm(range(0, len(df), chunk_size), desc=\"Processing chunks\"):\n",
    "        chunk = df.iloc[i:i+chunk_size]\n",
    "        filenames = chunk['path'].tolist()\n",
    "        audios = []\n",
    "        for filename in filenames:\n",
    "            audio, sr = librosa.load(os.path.join(audio_dir, filename), sr=None)\n",
    "            audios.append(Audio(audio, sr))\n",
    "        labels = chunk['label'].values\n",
    "\n",
    "        features = pipeline.transform(audios)\n",
    "        all_features.append(np.array(features))\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    X = np.concatenate(all_features, axis=0)\n",
    "    y = np.concatenate(all_labels, axis=0)\n",
    "    return X, y\n",
    "\n",
    "df_train, df_test = train_test_split(balanced_samples, test_size=0.2, random_state=42)\n",
    "X_train, y_train = process_in_chunks(df_train, feature_pipe)\n",
    "X_test, y_test = process_in_chunks(df_test, feature_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = make_pipeline(svm, verbose=True)\n",
    "model_pipe = model_pipe.fit(X_train, np.array(y_train))\n",
    "y_pred = model_pipe.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Create a folder for the model\n",
    "timestamp = time.strftime(\"%d_%m_%Y_T%H_%M_%S\")\n",
    "model_folder = f'trials/model_{timestamp}'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model_path = os.path.join(model_folder, 'model.joblib')\n",
    "dump(pipe, model_path)\n",
    "\n",
    "# Save evaluation metrics\n",
    "evaluation = {\n",
    "  \"architecture\": str([step[0] for step in pipe.steps]),\n",
    "  \"samples_per_class\": samples,\n",
    "  \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "  \"classification_report\": classification_report(y_test, y_pred, output_dict=True),\n",
    "  \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist()\n",
    "}\n",
    "\n",
    "# Save evaluation as JSON\n",
    "eval_path = os.path.join(model_folder, 'evaluation.json')\n",
    "with open(eval_path, 'w') as f:\n",
    "  json.dump(evaluation, f, indent=4)\n",
    "\n",
    "print(f\"Model and evaluation saved in folder: {model_folder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
