{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from preprocessing import silence_removal, noise_reduction, volume_normalization, quality_enhancer\n",
    "from feature_extraction.mfcc import MFCC\n",
    "from models.svm import SVM\n",
    "from audio import Audio\n",
    "\n",
    "original_metadata_path = os.path.join(\".\", \"data\", \"original_data_labeled.tsv\")\n",
    "filtered_metadata_path = os.path.join(\".\", \"data\", \"filtered_data_labeled.tsv\")\n",
    "audio_dir = os.path.join(\".\", \"data\", \"filtered_clips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove records of erroneous data (e.g. missing or corrupted audio files) from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(filtered_metadata_path):\n",
    "  df = pd.read_csv(original_metadata_path, sep='\\t')\n",
    "\n",
    "  valid_indices = []\n",
    "  for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking files\"):\n",
    "    file_path = os.path.join(audio_dir, row['path'])\n",
    "    if os.path.exists(file_path):\n",
    "      valid_indices.append(idx)\n",
    "\n",
    "  # Use only records with existing files\n",
    "  df = df.loc[valid_indices]\n",
    "\n",
    "  # Save the filtered DataFrame to a new TSV file\n",
    "  df.to_csv(filtered_metadata_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "df = pd.read_csv(filtered_metadata_path, sep='\\t')\n",
    "# Drop unnecessary columns\n",
    "df.drop(columns=['client_id', 'sentence', 'age', 'gender', 'accent'], inplace=True, errors='ignore')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a 2D histogram (heatmap) of upvotes vs downvotes\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist2d(df['up_votes'], df['down_votes'], bins=(10, 10), range=[(0, 3), (0, 3)], cmap='viridis')\n",
    "plt.colorbar(label='Frequency')\n",
    "\n",
    "plt.title(\"2D Histogram of Upvotes vs Downvotes\")\n",
    "plt.xlabel(\"Upvotes\")\n",
    "plt.ylabel(\"Downvotes\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 2000 # df['label'].value_counts().min()\n",
    "balanced_samples = pd.DataFrame()\n",
    "for cls in range(4):\n",
    "    cls_df = df[df['label'] == cls]\n",
    "    sampled = cls_df.sample(n=samples, random_state=42)  # Random sampling\n",
    "    balanced_samples = pd.concat([balanced_samples, sampled])\n",
    "\n",
    "def load_audio_file(file_path):\n",
    "    try:\n",
    "        return librosa.load(file_path)\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "X, Y = [], []\n",
    "error = 0\n",
    "for row in tqdm(balanced_samples.itertuples(), desc=\"Loading audio files\"):\n",
    "    audio, sr = load_audio_file(os.path.join(audio_dir, row.path))\n",
    "\n",
    "    if audio is None:\n",
    "        error += 1\n",
    "    else:\n",
    "        x = Audio(audio, sr)\n",
    "        X.append(x)\n",
    "        Y.append(row.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42, stratify=Y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_reducer = noise_reduction.NoiseReducer()\n",
    "silence_remover = silence_removal.SilenceRemover()\n",
    "mfcc = MFCC()\n",
    "svm = SVM()\n",
    "\n",
    "pipe = make_pipeline(noise_reducer, silence_remover, mfcc, svm, verbose=True) \n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.fit(X_train, np.array(y_train))\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Create a folder for the model\n",
    "model_folder = f'trials/model_{int(time.time())}'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model_path = os.path.join(model_folder, 'model.joblib')\n",
    "dump(pipe, model_path)\n",
    "\n",
    "# Save evaluation metrics\n",
    "evaluation = {\n",
    "  \"accuracy\": float(accuracy_score(y_test, y_pred)),\n",
    "  \"classification_report\": classification_report(y_test, y_pred, output_dict=True),\n",
    "  \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist()\n",
    "}\n",
    "\n",
    "# Save evaluation as JSON\n",
    "eval_path = os.path.join(model_folder, 'evaluation.json')\n",
    "with open(eval_path, 'w') as f:\n",
    "  json.dump(evaluation, f, indent=4)\n",
    "\n",
    "print(f\"Model and evaluation saved in folder: {model_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "loaded_pipeline = load('trials/model_1744398148.094835.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
