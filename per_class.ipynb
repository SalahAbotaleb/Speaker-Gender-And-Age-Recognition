{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7135e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "X_train = joblib.load('./trials/features/hfcc150_pitch_range/X_train.joblib')\n",
    "X_test = joblib.load('./trials/features/hfcc150_pitch_range/X_test.joblib')\n",
    "\n",
    "y_train = joblib.load(r'trials\\features\\48k_mfcc_extra_hfcc_extra\\y_train.joblib')\n",
    "y_test = joblib.load(r'trials\\features\\48k_mfcc_extra_hfcc_extra\\y_test.joblib')\n",
    "\n",
    "X_train2= joblib.load(r'trials\\features\\48k_mfcc_extra_hfcc_extra\\X_train.joblib')\n",
    "X_test2= joblib.load(r'trials\\features\\48k_mfcc_extra_hfcc_extra\\X_test.joblib')\n",
    "\n",
    "X_train_combined = np.concatenate((X_train2[:,:150], X_train2[:,7*75:9*75], X_train[:,-1:]), axis=1)\n",
    "X_test_combined = np.concatenate((X_test2[:,:150], X_test2[:,7*75:9*75], X_test[:,-1:]), axis=1)\n",
    "\n",
    "x_gender_train = np.concatenate((X_train2[:,:150], X_train2[:,7*75:9*75], X_train[:,-1:]), axis=1)\n",
    "y_gender_train = y_train % 2\n",
    "\n",
    "x_gender_test = np.concatenate((X_test2[:,:150], X_test2[:,7*75:9*75], X_test[:,-1:]), axis=1)\n",
    "y_gender_test = y_test % 2\n",
    "\n",
    "x_age_train = np.concatenate((X_train2[:,:150], X_train2[:,7*75:9*75], X_train[:,-1:]), axis=1)\n",
    "y_age_train = y_train // 2\n",
    "\n",
    "x_age_test = np.concatenate((X_test2[:,:150], X_test2[:,7*75:9*75], X_test[:,-1:]), axis=1)\n",
    "y_age_test = y_test // 2\n",
    "\n",
    "female_train = y_train % 2 == 1\n",
    "x_female_train_all = np.concatenate((X_train2[:,:150], X_train2[:,525:675],X_train2[:,750:900],X_train2[:,975:1050]), axis=1)\n",
    "x_female_train = x_female_train_all[female_train]\n",
    "y_female_train = y_train[female_train]\n",
    "\n",
    "female_test = y_test % 2 == 1\n",
    "x_female_test_all = np.concatenate((X_test2[:,:150], X_test2[:,525:675],X_test2[:,750:900],X_test2[:,975:1050]), axis=1)\n",
    "x_female_test = x_female_test_all[female_test]\n",
    "y_female_test = y_test[female_test]\n",
    "\n",
    "male_train = y_train % 2 == 0\n",
    "x_male_train_all = np.concatenate((X_train2[:,:150], X_train2[:,7*75:9*75]), axis=1)\n",
    "x_male_train = x_male_train_all[male_train]\n",
    "y_male_train = y_train[male_train] // 2\n",
    "\n",
    "male_test = y_test % 2 == 0\n",
    "x_male_test_all = np.concatenate((X_test2[:,:150], X_test2[:,7*75:9*75]), axis=1)\n",
    "x_male_test = x_male_test_all[male_test]\n",
    "y_male_test = y_test[male_test] // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34780835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def oversample_minority(x, y):\n",
    "  unique, counts = np.unique(y, return_counts=True)\n",
    "  oversample_value = unique[np.argmin(counts)]\n",
    "  true_indices = np.where(y == oversample_value)[0]\n",
    "  false_indices = np.where(y != oversample_value)[0]\n",
    "\n",
    "  true_oversampled = resample(\n",
    "    true_indices,\n",
    "    replace=True,\n",
    "    n_samples=len(false_indices),\n",
    "    random_state=42\n",
    "  )\n",
    "\n",
    "  balanced_indices = np.concatenate([false_indices, true_oversampled])\n",
    "  np.random.shuffle(balanced_indices)\n",
    "\n",
    "  x_balanced = x[balanced_indices]\n",
    "  y_balanced = y[balanced_indices]\n",
    "\n",
    "  return x_balanced, y_balanced\n",
    "\n",
    "def undersample_majority(x, y):\n",
    "  unique, counts = np.unique(y, return_counts=True)\n",
    "  undersample_value = unique[np.argmax(counts)]\n",
    "  true_indices = np.where(y == undersample_value)[0]\n",
    "  false_indices = np.where(y != undersample_value)[0]\n",
    "  \n",
    "  true_undersampled = resample(\n",
    "    true_indices,\n",
    "    replace=False,\n",
    "    n_samples=len(false_indices),\n",
    "    random_state=42\n",
    "  )\n",
    "\n",
    "  balanced_indices = np.concatenate([false_indices, true_undersampled])\n",
    "  np.random.shuffle(balanced_indices)\n",
    "\n",
    "  x_balanced = x[balanced_indices]\n",
    "  y_balanced = y[balanced_indices]\n",
    "\n",
    "  return x_balanced, y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ec9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "y_class_0 = y_train == 0\n",
    "\n",
    "skf = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "train_idx, val_idx = next(skf.split(X_train_combined, y_class_0))\n",
    "\n",
    "X_train_fold, X_val_fold = X_train_combined[train_idx], X_train_combined[val_idx]\n",
    "y_train_fold, y_val_fold = y_class_0[train_idx], y_class_0[val_idx]\n",
    "\n",
    "clf = SVC(kernel='rbf', C=1000, gamma=0.0001, random_state=42, class_weight='balanced')\n",
    "clf.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "y_val_pred_0 = clf.predict(X_val_fold)\n",
    "y_val_pred_proba_0 = clf.predict_proba(X_val_fold)\n",
    "print('Accuracy: %.3f' % (accuracy_score(y_val_fold, y_val_pred_0)))\n",
    "print(classification_report(y_val_fold, y_val_pred_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "351a0933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      7610\n",
      "        True       0.96      0.89      0.92      1030\n",
      "\n",
      "    accuracy                           0.98      8640\n",
      "   macro avg       0.97      0.94      0.96      8640\n",
      "weighted avg       0.98      0.98      0.98      8640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_class_1 = y_train == 1\n",
    "\n",
    "skf = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "train_idx, val_idx = next(skf.split(X_train_combined, y_class_1))\n",
    "\n",
    "X_train_fold, X_val_fold = X_train_combined[train_idx], X_train_combined[val_idx]\n",
    "y_train_fold, y_val_fold = y_class_1[train_idx], y_class_1[val_idx]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights='distance', n_jobs=-1)\n",
    "knn.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "y_val_pred_1 = knn.predict(X_val_fold)\n",
    "y_val_pred_proba_1 = knn.predict_proba(X_val_fold)\n",
    "print('Accuracy: %.3f' % (accuracy_score(y_val_fold, y_val_pred_1)))\n",
    "print(classification_report(y_val_fold, y_val_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "db198c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      7718\n",
      "        True       0.90      0.90      0.90       922\n",
      "\n",
      "    accuracy                           0.98      8640\n",
      "   macro avg       0.94      0.94      0.94      8640\n",
      "weighted avg       0.98      0.98      0.98      8640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_class_2 = y_train == 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "train_idx, val_idx = next(skf.split(X_train_combined, y_class_2))\n",
    "\n",
    "X_train_fold, X_val_fold = X_train_combined[train_idx], X_train_combined[val_idx]\n",
    "y_train_fold, y_val_fold = y_class_2[train_idx], y_class_2[val_idx]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights='distance', n_jobs=-1)\n",
    "knn.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "y_val_pred_2 = knn.predict(X_val_fold)\n",
    "y_val_pred_proba_2 = knn.predict_proba(X_val_fold)\n",
    "print('Accuracy: %.3f' % (accuracy_score(y_val_fold, y_val_pred_2)))\n",
    "print(classification_report(y_val_fold, y_val_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ded0ae74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      7858\n",
      "        True       0.95      0.95      0.95       782\n",
      "\n",
      "    accuracy                           0.99      8640\n",
      "   macro avg       0.97      0.97      0.97      8640\n",
      "weighted avg       0.99      0.99      0.99      8640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_class_3 = y_train == 3\n",
    "\n",
    "skf = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)\n",
    "train_idx, val_idx = next(skf.split(X_train_combined, y_class_3))\n",
    "\n",
    "X_train_fold, X_val_fold = X_train_combined[train_idx], X_train_combined[val_idx]\n",
    "y_train_fold, y_val_fold = y_class_3[train_idx], y_class_3[val_idx]\n",
    "X_train_balanced, y_train_balanced = X_train_fold, y_train_fold\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights='distance', n_jobs=-1)\n",
    "knn.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_val_pred_3 = knn.predict(X_val_fold)\n",
    "y_val_pred_proba_3 = knn.predict_proba(X_val_fold)\n",
    "print('Accuracy: %.3f' % (accuracy_score(y_val_fold, y_val_pred_3)))\n",
    "print(classification_report(y_val_fold, y_val_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a7e1083a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples with multiple classifiers predicting True: 1742/8640\n",
      "Number of examples with no classifier predicting True: 1984/8640\n",
      "Accuracy: 0.852\n",
      "Accuracy: 0.822\n"
     ]
    }
   ],
   "source": [
    "# Stack the predictions for each class\n",
    "y_val_preds = np.vstack([y_val_pred_0, y_val_pred_1, y_val_pred_2, y_val_pred_3])\n",
    "y_val_preds_proba = np.vstack([y_val_pred_proba_0[:, 1].T, y_val_pred_proba_1[:, 1].T, y_val_pred_proba_2[:, 1].T, y_val_pred_proba_3[:, 1].T])\n",
    "\n",
    "# Count how many classifiers predict True for each example\n",
    "num_true_preds = np.sum(y_val_preds, axis=0)\n",
    "\n",
    "# Count how many examples have more than one classifier predicting True\n",
    "num_multiple_true = np.sum(num_true_preds > 1)\n",
    "\n",
    "print(f\"Number of examples with multiple classifiers predicting True: {num_multiple_true}/{len(y_val_preds[0])}\")\n",
    "print(f\"Number of examples with no classifier predicting True: {sum(num_true_preds == 0)}/{len(y_val_preds[0])}\")\n",
    "\n",
    "overall_pred = np.argmax(y_val_preds, axis=0)\n",
    "print('Accuracy: %.3f' % (accuracy_score(y_val_fold, overall_pred)))\n",
    "\n",
    "overall_pred_proba = np.argmax(y_val_preds_proba, axis=0)\n",
    "print('Accuracy: %.3f' % (accuracy_score(y_val_fold, overall_pred_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b7ac2896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://media.tenor.com/ekebXEH4uBEAAAAS/monkey-laught.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(url=\"https://media.tenor.com/ekebXEH4uBEAAAAS/monkey-laught.gif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28547d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
